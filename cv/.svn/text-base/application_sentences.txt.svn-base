GENERIC EMAIL

I've been thinking about a remark Andrew McCallum made to me a whileback about the value of problem-driven research, and the more I thinkabout it, the more I realize I that that is a direction I wantto move in. I see lots of open problems in the modeling of economic,financial, and energy data, which has become compelling to me as Ithink about information needs back home in Uruguay.  Theresearch firm I'm working for this summer (State Street Research, here inCambridge)sees an enormous amount of data daily -- something like 15% of dailyworld trade voIume. I was looking at your research page and I think yourwork on sparse, large scale ML is hugely relevant, and I'd like to learnmore about it.So, I thought I would send out a feeler and ask....might you want/haveany openings for a post-doc starting in fall/winter?


ML SCHOOL APPLICATION/RESEARCH STATEMENT

I am interested in the problem of efficient decision-making under uncertainty. That is, how can we deal with the dual problem of having too much information for a task, while on the other hand, sometimes not having enough? In my PhD research, I studied the problem of sequential decision-making in the presence of too-large state and action spaces. Given a logical model of state transitions, we were able to exploit the known structure of the dynamics in order to collapse the number of distinct options under consideration at each decision point.  The availability of a model was crucial for informing what to ignore and what to pay attention to. So how would we go about uncovering that model and that structure in the first place, when all we have at our disposal is large amounts of unstructured data?  Over the next months, I'll be undertaking a new project on modeling a large-scale investor behavior in emerging markets. What is it about emerging markets that makes investors behave in a certain way? Can we uncover particular patterns of activity to characterize these economies? In fact, there is a huge need for applying machine learning tools to fields as diverse as finance, developing economics, epidemiology, the environment, and so on. It is in the context of these problems -- concrete, real-world problems -- that I am interested in working in the future.  Building on the techniques I know and those to which IÕve been exposed informally, I believe attending the Machine Learning Summer School would provide a systematic, concentrated way to gain exposure and depth of experience in the range of current tools available.  I very much look forward to being able to participate in this unique and valuable opportunity. 


CV SUMMARY

Academic Background:- Doctor of Philosophy., Electrical Engineering and Computer Science, Dec 2007,  Massachusetts Institute of Technology.- Master of Science, Electrical Engineering and Computer Science,  Feb 2003,  Massachusetts Institute of Technology.- Bachelor of Science, Computer Science and Engineering,  Dec 1999,  Michigan State University.Research Interests:Decision-making under uncertainty, Probabilistic models, Reinforcement learning.Selected Papers:Natalia H. Gardiol, "Relational Envelope-based Planning", Ph.D. Thesis, MIT CSAIL, December 2007. Natalia H. Gardiol and Leslie Pack Kaelbling, "Action-space partitioning for planning", AAAI 2007, July 2007. Natalia H. Gardiol and Leslie Pack Kaelbling, "Computing action equivalences for planning",ICAPS 2006 Doctoral Consortium, June 2006. [pdf] [bib]Natalia H. Gardiol and Leslie Pack Kaelbling, "Computing action equivalences for planning under time-constraints", MIT Technical Report MIT-CSAIL-TR-2006-022, December 2005.Natalia H. Gardiol and Leslie Pack Kaelbling, "Envelope-based Planning in Relational MDPs", Advances in Neural Information Processing Systems 16 (NIPS*2003) Natalia H. Gardiol, "Applying Probabilistic Rules To Relational Worlds", M.S. Thesis, MIT AI Lab, November 2002. Sarah Finney, Natalia H. Gardiol, Leslie Pack Kaelbling, Tim Oates, "The Thing That We Tried Didn't Work Very Well: Deictic Representation in Reinforcement Learning", 18th International Conference on Uncertainty in Artificial Intelligence, Edmonton, August 2002 (UAI-02). Sarah Finney, Natalia H. Gardiol, Leslie Pack Kaelbling, Tim Oates, "Learning with Deictic Representation", MIT AI Lab Technical Report (AIM-2002-006), April 2002. Natalia Hernandez Gardiol and Sridhar Mahadevan, "Hierarchical Memory-based Reinforcement Learning", Advances in Neural Information Processing Systems 13, (NIPS*2000). MIT Press, Cambridge, 2001. 